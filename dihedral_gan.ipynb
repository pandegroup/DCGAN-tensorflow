{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook addresses the question, \"Can we represent a molecule as a graph via a 1D column vector or a 2D matrix of fixed length, with maximum number of atoms n_rows?\" Then, can we use this representation to learn neural fingerprints? E.g., can we make an aromatic ring detector? \n",
    "\n",
    "Scheme:\n",
    "feature_matrix = X\n",
    "for each ligand:\n",
    "    choose a central atom. this can be the atom (node) that minimizes distance to furthest heavy atom in graph.\n",
    "    set first row of X to be this central atom\n",
    "    set next four rows to be the atoms bonded to that centrl atom\n",
    "        set zeros for rows where row ind > n_bonds of atom\n",
    "    for each of those atoms:\n",
    "        repeat. find their neighbors. add to matrix.\n",
    "\n",
    "algorithm: breadth-first search:\n",
    "1. create networkx graph based on molecule\n",
    "2. find \"central\" atom (different strategies)\n",
    "3. define atom matrix of size (1+4+4*3^(L-1)) x (n_features_per_atom)\n",
    "4. start atom queue q\n",
    "5. central_atom.layer = 0; central_atom.row_idx = 0;\n",
    "6. q.enqueue(central_atom)\n",
    "7. define adjacency matrix of size (1+4+4*3^(L-1)) x 4\n",
    "\n",
    "def get_row_idx(curr_layer, prev_row_idx, curr_neighbor_idx):\n",
    "    if curr_layer == 0:\n",
    "        return(0)\n",
    "    if curr_layer == 1:\n",
    "        row_idx = 1 + curr_neighbor_idx\n",
    "    if layer == 2:\n",
    "        last_max = 5\n",
    "        row_idx = last_max + (3*(prev_row_idx-last_max)) + curr_neighbor_idx\n",
    "    if layer > 2:\n",
    "        last_max = 5 + 4*3^(curr_layer-2) \n",
    "        row_idx = last_max + 3*(prev_row_idx-last_max) + curr_neighbor_idx\n",
    "    return(row_idx)\n",
    "    \n",
    "\n",
    "while q.is_not_empty():\n",
    "    a = q.dequeue()\n",
    "    a.visited = True\n",
    "    for n_idx, n in enumerate(a.neighbors()):\n",
    "        if not n.visited:\n",
    "            row_idx = c\n",
    "            n.layer = a.layer + 1\n",
    "            row_idx = get_row_idx(n.layer, a.row_idx, n_idx)\n",
    "            n.row_idx = row_idx\n",
    "            adj_matrix[a.row_idx][n_idx] = n.row_idx\n",
    "            atom_matrix[row_idx][elem_to_idx[n.elem]] = 1\n",
    "\n",
    "input_matrix = tf.concat([atom_matrix, atom_matrix[adj_matrix[:,0]], atom_matrix[adj_matrix[:,1]], atom_matrix[adj_matrix[:,2]], atom_matrix[adj_matrix[:,3]]\n",
    "\n",
    "neural net:\n",
    "h1 = relu([tf.zeros([n_features_per_atom, 4]) * input_matrix + bias))\n",
    "h1_conc = tf.concat([h1, h1[adj_matrix[:,0], ..., h1[adj_matrix[:,3])\n",
    "\n",
    "repeat h1 to get h2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dihedral predictor pseudocode:\n",
    "\n",
    "get bonds for molecule\n",
    "create networkx graph out of molecule (use atom indices)\n",
    "\n",
    "for each edge:\n",
    "   for neighbor_i in atom_i.neighbors():\n",
    "       if neighbor_i == atom_j: continue\n",
    "       for neighbor_j in atom_j.neighbors():\n",
    "           if neighbor_j == atom_i: continue\n",
    "           dihedrals.append((neighbor_i, atom_i, neighbor_j, atom_j))\n",
    "           check to make sure (atom_j, neighbor_j, atom_i, neighbor_i)) not already in list\n",
    "\n",
    "for dihedral in dihedrals:\n",
    "    angle =  rdMolTransforms.GetDihedralDeg(c, 0,1,2,3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem, rdMolTransforms\n",
    "import os\n",
    "import fnmatch\n",
    "import numpy as np\n",
    "import deepchem as dc\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_torsions_angles(mol):\n",
    "    torsion_tuples = []\n",
    "    for bond in mol.GetBonds():\n",
    "        atom_i = bond.GetBeginAtom()\n",
    "        atom_j = bond.GetEndAtom()\n",
    "        if atom_i.IsInRing() or atom_j.IsInRing():\n",
    "            continue\n",
    "        for neighbor_i in atom_i.GetNeighbors():\n",
    "            if neighbor_i.GetIdx() == atom_j.GetIdx():\n",
    "                continue\n",
    "            \n",
    "            for neighbor_j in atom_j.GetNeighbors():\n",
    "                if neighbor_j.GetIdx() == atom_i.GetIdx():\n",
    "                    continue\n",
    "                torsion_tuple = (neighbor_i.GetIdx(), atom_i.GetIdx(), atom_j.GetIdx(), neighbor_j.GetIdx())\n",
    "                reverse_torsion_tuple = (neighbor_j.GetIdx(), atom_j.GetIdx(), atom_i.GetIdx(), neighbor_i.GetIdx())\n",
    "                if torsion_tuple not in torsion_tuples and reverse_torsion_tuple not in torsion_tuples:\n",
    "                    torsion_tuples.append(torsion_tuple)\n",
    "    c = mol.GetConformer(0)\n",
    "    torsions = []\n",
    "    torsion_matrix = np.zeros((250,1))\n",
    "    torsion_indices = np.zeros((250,200,4)).astype(np.uint8)\n",
    "    for i, torsion_tuple in enumerate(torsion_tuples):\n",
    "        torsion_matrix[i] = np.abs(rdMolTransforms.GetDihedralRad(c, *torsion_tuple))\n",
    "        torsion_indices[i][torsion_tuple[0]][0] = 1\n",
    "        torsion_indices[i][torsion_tuple[1]][1] = 1\n",
    "        torsion_indices[i][torsion_tuple[2]][2] = 1\n",
    "        torsion_indices[i][torsion_tuple[3]][3] = 1\n",
    "    return((torsion_indices, csr_matrix(torsion_matrix)))\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def featurize_mols(mol_files):\n",
    "    featurizer = AdjacencyFingerprint(max_n_atoms=200)\n",
    "    features = []\n",
    "    for mol_file in mol_files:\n",
    "        mol = Chem.MolFromMol2File(mol_file)\n",
    "        if mol is None:\n",
    "            features.append(None)\n",
    "            continue\n",
    "        torsions = get_torsions_angles(mol)\n",
    "        graph_feat = featurizer.featurize([mol])[0]\n",
    "        features.append((mol_file, torsions, graph_feat))\n",
    "    return(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from deepchem.feat.graph_features import ConvMolFeaturizer\n",
    "from deepchem.feat.adjacency_fingerprints import AdjacencyFingerprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "feature_file = \"./dihedral_features_pdbbind.pkl\"\n",
    "#if not os.path.exists(feature_file):\n",
    "if 1== 1:\n",
    "    pdbbind_dir = \"/home/evan/Documents/deep_docking/datasets/v2015/\"\n",
    "    def find_files(directory, pattern):\n",
    "        for root, dirs, files in os.walk(directory):\n",
    "            for basename in files:\n",
    "                if fnmatch.fnmatch(basename, pattern):\n",
    "                    filename = os.path.join(root, basename)\n",
    "                    yield filename\n",
    "    ligand_files = [f for f in find_files(pdbbind_dir, \"*ligand.mol2\")][:128]\n",
    "    features = featurize_mols(ligand_files)\n",
    "    with open(feature_file, \"wb\") as f:\n",
    "        pickle.dump(features, f, protocol=2)\n",
    "else:\n",
    "    with open(feature_file, \"rb\") as f:\n",
    "        features = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = [f for f in features if f is not None and len(np.where(f[1][1].toarray() == 0)[0]) < 250][0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen.h1\n",
      "Tensor(\"generator/add_1:0\", shape=(10000, 1), dtype=float32)\n",
      "gen.h1\n",
      "Tensor(\"generator_1/add_1:0\", shape=(10000, 1), dtype=float32)\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from model import DCGAN\n",
    "gan = DCGAN(n_layers=2, batch_size=1,\n",
    "                                 n_atom_types=1,\n",
    "                                 max_n_atoms=200,\n",
    "                                 max_valence=6,\n",
    "                                 n_tasks=1,\n",
    "                                 learning_rate=1e-3,\n",
    "                                 L_list = [50, 50, 50, 50],\n",
    "                                 epsilon=1e-8,\n",
    "                                 beta1=0.9,\n",
    "                                 dropout=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 0\n",
      "0.60805\n",
      "1.49907\n",
      "Training epoch 1\n",
      "Training epoch 2\n",
      "Training epoch 3\n",
      "Training epoch 4\n",
      "Training epoch 5\n",
      "Training epoch 6\n",
      "Training epoch 7\n",
      "Training epoch 8\n",
      "Training epoch 9\n",
      "Training epoch 10\n",
      "0.52482\n",
      "1.57451\n",
      "Training epoch 11\n",
      "Training epoch 12\n",
      "Training epoch 13\n",
      "Training epoch 14\n",
      "Training epoch 15\n",
      "Training epoch 16\n",
      "Training epoch 17\n",
      "Training epoch 18\n",
      "Training epoch 19\n",
      "Training epoch 20\n",
      "0.460055\n",
      "1.64954\n",
      "Training epoch 21\n",
      "Training epoch 22\n",
      "Training epoch 23\n",
      "Training epoch 24\n",
      "Training epoch 25\n",
      "Training epoch 26\n",
      "Training epoch 27\n",
      "Training epoch 28\n",
      "Training epoch 29\n",
      "Training epoch 30\n",
      "0.412811\n",
      "1.72222\n",
      "Training epoch 31\n",
      "Training epoch 32\n",
      "Training epoch 33\n",
      "Training epoch 34\n",
      "Training epoch 35\n",
      "Training epoch 36\n",
      "Training epoch 37\n",
      "Training epoch 38\n",
      "Training epoch 39\n",
      "Training epoch 40\n",
      "0.37117\n",
      "1.79128\n",
      "Training epoch 41\n",
      "Training epoch 42\n",
      "Training epoch 43\n",
      "Training epoch 44\n",
      "Training epoch 45\n",
      "Training epoch 46\n",
      "Training epoch 47\n",
      "Training epoch 48\n",
      "Training epoch 49\n",
      "Training epoch 50\n",
      "0.335666\n",
      "1.85624\n",
      "Training epoch 51\n",
      "Training epoch 52\n",
      "Training epoch 53\n",
      "Training epoch 54\n",
      "Training epoch 55\n",
      "Training epoch 56\n",
      "Training epoch 57\n",
      "Training epoch 58\n",
      "Training epoch 59\n",
      "Training epoch 60\n",
      "0.304016\n",
      "1.91721\n",
      "Training epoch 61\n",
      "Training epoch 62\n",
      "Training epoch 63\n",
      "Training epoch 64\n",
      "Training epoch 65\n",
      "Training epoch 66\n",
      "Training epoch 67\n",
      "Training epoch 68\n",
      "Training epoch 69\n",
      "Training epoch 70\n",
      "0.27589\n",
      "1.97461\n",
      "Training epoch 71\n",
      "Training epoch 72\n",
      "Training epoch 73\n",
      "Training epoch 74\n",
      "Training epoch 75\n",
      "Training epoch 76\n",
      "Training epoch 77\n",
      "Training epoch 78\n",
      "Training epoch 79\n",
      "Training epoch 80\n",
      "0.251346\n",
      "2.02896\n",
      "Training epoch 81\n",
      "Training epoch 82\n",
      "Training epoch 83\n",
      "Training epoch 84\n",
      "Training epoch 85\n",
      "Training epoch 86\n",
      "Training epoch 87\n",
      "Training epoch 88\n",
      "Training epoch 89\n",
      "Training epoch 90\n",
      "0.230285\n",
      "2.08075\n",
      "Training epoch 91\n",
      "Training epoch 92\n",
      "Training epoch 93\n",
      "Training epoch 94\n",
      "Training epoch 95\n",
      "Training epoch 96\n",
      "Training epoch 97\n",
      "Training epoch 98\n",
      "Training epoch 99\n",
      "[[ 14.97169113]\n",
      " [ 19.8886261 ]\n",
      " [ 14.36204147]]\n"
     ]
    }
   ],
   "source": [
    "gan.train(features, n_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = gan.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  8.26161671],\n",
       "       [ 18.00482559],\n",
       "       [ 14.10464096],\n",
       "       ..., \n",
       "       [ 21.83512688],\n",
       "       [ 14.42951775],\n",
       "       [ 21.71645737]], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npSfnAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6689176450>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(res, bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.91292151],\n",
       "       [ 3.09695411],\n",
       "       [ 1.06725919],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[0][1][1].toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.91292151],\n",
       "       [ 3.09695411],\n",
       "       [ 1.06725919],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[0][1][1].toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = []\n",
    "for i in range(0,100):\n",
    "    preds.append(gan.predict(features)[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.944489"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features[0][2].atom_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
